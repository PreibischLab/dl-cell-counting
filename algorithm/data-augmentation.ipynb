{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is used for testing the posibilities of the data augmentation in keras. The functionality will added to the 2D/3D networks once the tests are done. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# general imports\n",
    "import sys,os,time,random\n",
    "from os import walk\n",
    "import pickle\n",
    "\n",
    "# scientific computing\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('Agg');\n",
    "import matplotlib.pyplot as plt\n",
    "plt.set_cmap('jet');\n",
    "import skimage\n",
    "from skimage.io import imread, imsave\n",
    "import scipy\n",
    "\n",
    "from __future__ import print_function\n",
    "# machine learning stuff\n",
    "import tensorflow as tf\n",
    "import keras \n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"keras\", keras.__version__)\n",
    "print(\"tensorflow\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check the backend the ordering of the channels\n",
    "print(keras.backend.backend())\n",
    "print(keras.backend.image_dim_ordering())\n",
    "print(K.image_data_format())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Setup for the gpu: \n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
    "\n",
    "get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# check the output of the command above\n",
    "tf.device(\"/gpu:0\")\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "# this pone should help with the images of the large size\n",
    "config = tf.ConfigProto(allow_soft_placement=True)\n",
    "config.gpu_options.allocator_type = 'BFC'\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this part is necessary to set the params from the command line\n",
    "import sys\n",
    "import argparse\n",
    "\n",
    "if len(sys.argv) == 3 and sys.argv[1] == \"-f\": #on jupyter\n",
    "    sys.argv = ['']\n",
    "    \n",
    "parser = argparse.ArgumentParser(description='Count-ception')\n",
    "\n",
    "parser.add_argument('-seed', type=int, nargs='?',default=0, help='random seed for split and init')\n",
    "parser.add_argument('-nsamples', type=int, nargs='?',default=32, help='Number of samples (N) in train and valid')\n",
    "# TODO: Is it used ? \n",
    "parser.add_argument('-stride', type=int, nargs='?',default=1, help='The args.stride at the initial layer')\n",
    "# TODO: Is it used ?\n",
    "parser.add_argument('-lr', type=float, nargs='?',default=0.00005, help='This will set the learning rate ')\n",
    "parser.add_argument('-kern', type=str, nargs='?',default=\"sq\", help='This can be gaus or sq')\n",
    "parser.add_argument('-cov', type=float, nargs='?',default=1, help='This is the covariance when kern=gaus')\n",
    "parser.add_argument('-scale', type=int, nargs='?',default=1, help='Scale the input image and labels')\n",
    "parser.add_argument('-data', type=str, nargs='?',default=\"cells\", help='Dataset folder')\n",
    "parser.add_argument('-framesize', type=int, nargs='?',default=256, help='Size of the images processed at once')\n",
    "\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set the passed parameters here if you forgot them\n",
    "args.framesize = 256\n",
    "args.scale = 1\n",
    "args.nsamples = 32\n",
    "\n",
    "print(args)\n",
    "print(keras.backend.image_data_format())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# how much to extend the initial image \n",
    "patch_size = int(32)\n",
    "framesize = int(args.framesize/args.scale)\n",
    "channels = int(3)\n",
    "framesize_h = framesize_w = framesize\n",
    "noutputs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "paramfilename = str(args.scale) + \"-\" + str(patch_size) + \"-\" + args.data + \"-\" + args.kern + str(args.cov) + \"_params.p\"\n",
    "datasetfilename = str(args.scale) + \"-\" + str(patch_size) + \"-\" + str(framesize) + \"-\" + args.kern + str(args.stride) + \"-\" + args.data + \"-\" + str(args.cov) + \"-dataset.p\"\n",
    "print(paramfilename)\n",
    "print(datasetfilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#reproducibility\n",
    "random.seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "tf.set_random_seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if (args.kern == \"sq\"):\n",
    "    ef = ((patch_size/args.stride)**2.0)\n",
    "elif (args.kern == \"gaus\"):\n",
    "    ef = 1.0\n",
    "print(\"ef\", ef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# input shape is the image shape without the pathces\n",
    "input_shape = (framesize, framesize, channels)\n",
    "ext_shape = (input_shape[0] + patch_size, input_shape[0] + patch_size, 1)\n",
    "\n",
    "print (input_shape, ext_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fucntions to see the results \n",
    "def genGausImage(framesize, mx, my, cov=1):\n",
    "    x, y = np.mgrid[0:framesize, 0:framesize]\n",
    "    pos = np.dstack((x, y))\n",
    "    mean = [mx, my]\n",
    "    cov = [[cov, 0], [0, cov]]\n",
    "    rv = scipy.stats.multivariate_normal(mean, cov).pdf(pos)\n",
    "    return rv/rv.sum()\n",
    "\n",
    "def getDensity(width, markers):\n",
    "    gaus_img = np.zeros((width,width))\n",
    "    for k in range(width):\n",
    "        for l in range(width):\n",
    "            if (markers[k,l] > 0.5):\n",
    "                gaus_img += genGausImage(len(markers),k-patch_size/2,l-patch_size/2,cov)\n",
    "    return gaus_img\n",
    "\n",
    "def getMarkersCells(labelPath, scale, size):  \n",
    "    labs = imread(labelPath)    \n",
    "    if len(labs.shape) == 2:\n",
    "        lab = labs[:,:]/255\n",
    "    elif len(labs.shape) == 3:\n",
    "        lab = labs[:,:,0]/255\n",
    "    else:\n",
    "        print(\"unknown label format\")\n",
    "    \n",
    "    binsize = [scale,scale]\n",
    "    out = np.zeros(size)\n",
    "    for i in range(binsize[0]):\n",
    "        for j in range(binsize[1]):\n",
    "            out = np.maximum(lab[i::binsize[0], j::binsize[1]], out)\n",
    "        \n",
    "    print(lab.sum(),out.sum())\n",
    "    assert np.allclose(lab.sum(),out.sum(), 1)\n",
    "    \n",
    "    return out\n",
    "\n",
    "def getCellCountCells(markers, x,y,h,w):\n",
    "    types = [0] * noutputs\n",
    "    for i in range(noutputs):\n",
    "        types[i] = (markers[y:y+h,x:x+w] == 1).sum()\n",
    "        #types[i] = (markers[y:y+h,x:x+w] != -1).sum()\n",
    "    return types\n",
    "\n",
    "def getLabelsCells(markers, img_pad, base_x, base_y, stride, scale):\n",
    "    \n",
    "    height = int ((img_pad.shape[0])/args.stride)\n",
    "    width = int ((img_pad.shape[1])/args.stride)\n",
    "    print(\"label size: \", height, width)\n",
    "    labels = np.zeros((noutputs, height, width))\n",
    "    if (args.kern == \"sq\"):\n",
    "        for y in range(0,height):\n",
    "            for x in range(0,width):\n",
    "                count = getCellCountCells(markers, x*args.stride,y*args.stride,patch_size,patch_size)  \n",
    "                for i in range(0,noutputs):\n",
    "                    labels[i][y][x] = count[i]\n",
    "\n",
    "    \n",
    "    elif (args.kern == \"gaus\"):\n",
    "        for i in range(0,noutputs):\n",
    "            labels[i] = getDensity(width, markers[base_y:base_y+width,base_x:base_x+width])\n",
    "    \n",
    "\n",
    "    count_total = getCellCountCells(markers, 0,0,framesize_h+patch_size,framesize_w+patch_size)\n",
    "    return labels, count_total\n",
    "\n",
    "def getTrainingExampleCells(img_raw, framesize_w, framesize_h, labelPath, base_x,  base_y, stride, scale):\n",
    "    \n",
    "    img = img_raw[base_y:base_y+framesize_h, base_x:base_x+framesize_w]\n",
    "    img_pad = np.pad(img[:,:,0], int ((patch_size)/2), \"constant\")\n",
    "    \n",
    "    markers = getMarkersCells(labelPath, scale, img_raw.shape[0:2])\n",
    "    markers = markers[base_y:base_y+framesize_h, base_x:base_x+framesize_w]\n",
    "    \n",
    "    # labels_not_squarified = np.pad(markers,  int ((patch_size)/2), \"constant\", constant_values=0)\n",
    "    \n",
    "    markers = np.pad(markers, patch_size, \"constant\", constant_values=0)\n",
    "    # img = np.array(markers.reshape((320, 320, 1)), dtype=np.float32).astype(np.uint8)\n",
    "    # plt.imshow(markers)\n",
    "    \n",
    "    labels, count  = getLabelsCells(markers, img_pad, base_x, base_y, args.stride, scale)\n",
    "    return img, labels, count, markers[None, patch_size:-patch_size, patch_size:-patch_size]\n",
    "    # return img, markers, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read the files from the test folder \n",
    "import glob\n",
    "\n",
    "# prefix = '/Users/kkolyva/'\n",
    "prefix = '/home/milkyklim/'\n",
    "folder = prefix + 'dl-cell-counting/algorithm/data/test-cells-small'\n",
    "folder_images = \"\" # 'images/'\n",
    "folder_labels = \"\" # 'labels/'\n",
    "img_ext = '.png'\n",
    "\n",
    "print('Images path:', folder + folder_images)\n",
    "print('Labels path:', folder + folder_labels)\n",
    "\n",
    "imgs = []\n",
    "\n",
    "for filename in glob.iglob(folder + folder_labels + \"/*dots\" + img_ext):\n",
    "    imgg = filename.replace(folder_labels + \"dots\", folder_images + \"cell\")\n",
    "    imgs.append([imgg,filename])\n",
    "    \n",
    "if len(imgs) == 0:\n",
    "    print(\"Issue with dataset\")\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read the files from the test folder \n",
    "import glob\n",
    "\n",
    "prefix = '/Users/kkolyva/'\n",
    "# prefix = '/home/milkyklim/Documents/other'\n",
    "folder = prefix + 'dl-cell-counting/algorithm/data/test-cells'\n",
    "img_ext = '.png'\n",
    "\n",
    "print('Full path:', folder)\n",
    "\n",
    "imgs = []\n",
    "\n",
    "for filename in glob.iglob(folder + \"/*dots\" + img_ext):\n",
    "    imgg = filename.replace(\"dots\",\"cell\")\n",
    "    imgs.append([imgg,filename])\n",
    "    \n",
    "if len(imgs) == 0:\n",
    "    print(\"Issue with dataset\")\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for path in imgs: \n",
    "    if (not os.path.isfile(path[0])):\n",
    "        print(path, \"bad\", path[0])\n",
    "    if (not os.path.isfile(path[1])):\n",
    "        print(path, \"bad\", path[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = []\n",
    "if (os.path.isfile(datasetfilename)):\n",
    "    print(\"reading\", datasetfilename)\n",
    "    dataset = pickle.load(open(datasetfilename, \"rb\" ))\n",
    "else:\n",
    "    dataset_x = []\n",
    "    dataset_y = []\n",
    "    dataset_c = []\n",
    "    print(len(imgs))\n",
    "    for path in imgs: \n",
    "\n",
    "        imgPath = path[0]\n",
    "        print(imgPath)\n",
    "\n",
    "        im = imread(imgPath)\n",
    "        img_raw_raw = im; # im[:, :, None] # .transpose([1,2,0])\n",
    "        \n",
    "        # img_raw = scipy.misc.imresize(img_raw_raw, (int(img_raw_raw.shape[0]/args.scale),int(img_raw_raw.shape[1]/args.scale)))\n",
    "        img_raw = img_raw_raw\n",
    "        print(img_raw_raw.shape,\" ->>>>\", img_raw.shape)\n",
    "\n",
    "        labelPath = path[1]\n",
    "        for base_x in range(0,img_raw.shape[0],framesize_h):\n",
    "            for base_y in range(0,img_raw.shape[1],framesize_w):\n",
    "                \n",
    "                if (img_raw.shape[1] - base_y < framesize_w) or (img_raw.shape[0] - base_x < framesize_h):\n",
    "                    print(\"!!!! Not adding image because size is\" , img_raw.shape[1] - base_y, img_raw.shape[0] - base_x)\n",
    "                    continue\n",
    "                    \n",
    "                img, lab, count = getTrainingExampleCells(img_raw, framesize_w, framesize_h, labelPath, base_y, base_x, args.stride, args.scale)\n",
    "                print(\"count \", count)\n",
    "                    \n",
    "                if img.shape[0:2] != (framesize_w,framesize_h):\n",
    "                    print(\"!!!! Not adding image because size is\" , img.shape[0:2])\n",
    "                    \n",
    "                else :   \n",
    "                    lab_est = [(l.sum()/ef).astype(np.int) for l in lab]\n",
    "                \n",
    "                    assert np.allclose(count,lab_est, 0)\n",
    "                \n",
    "                    dataset.append((img,lab,count))\n",
    "                    \n",
    "                    print(\"lab_est\", lab_est, \"img shape\", img.shape, \"label shape\", lab.shape)\n",
    "                    sys.stdout.flush()\n",
    "                    \n",
    "        print(\"dataset size\", len(dataset))\n",
    "                    \n",
    "    print(\"writing\", datasetfilename)\n",
    "    out = open(datasetfilename, \"wb\",0)\n",
    "    pickle.dump(dataset, out)\n",
    "    out.close()\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# alternative reading for the imagees\n",
    "dataset = []\n",
    "if (os.path.isfile(datasetfilename) and False):\n",
    "    print(\"reading\", datasetfilename)\n",
    "    dataset = pickle.load(open(datasetfilename, \"rb\" ))\n",
    "else:\n",
    "    dataset_x = []\n",
    "    dataset_y = []\n",
    "    dataset_c = []\n",
    "    dataset_l = []\n",
    "    print(len(imgs))\n",
    "    for path in imgs: \n",
    "\n",
    "        imgPath = path[0]\n",
    "        print(imgPath)\n",
    "\n",
    "        im = imread(imgPath)\n",
    "        img_raw_raw = im; # im[:, :, None] # .transpose([1,2,0])\n",
    "        \n",
    "        # img_raw = scipy.misc.imresize(img_raw_raw, (int(img_raw_raw.shape[0]/args.scale),int(img_raw_raw.shape[1]/args.scale)))\n",
    "        img_raw = img_raw_raw\n",
    "        print(img_raw_raw.shape,\" ->>>>\", img_raw.shape)\n",
    "\n",
    "        labelPath = path[1]\n",
    "        # these loops look useless \n",
    "        for base_x in range(0,img_raw.shape[0],framesize_h):\n",
    "            for base_y in range(0,img_raw.shape[1],framesize_w):\n",
    "                \n",
    "                if (img_raw.shape[1] - base_y < framesize_w) or (img_raw.shape[0] - base_x < framesize_h):\n",
    "                    print(\"!!!! Not adding image because size is\" , img_raw.shape[1] - base_y, img_raw.shape[0] - base_x)\n",
    "                    continue\n",
    "                    \n",
    "                img, lab, count, im_lab= getTrainingExampleCells(img_raw, framesize_w, framesize_h, labelPath, base_y, base_x, args.stride, args.scale)\n",
    "                print(\"count \", count)\n",
    "                    \n",
    "                if img.shape[0:2] != (framesize_w,framesize_h):\n",
    "                    print(\"!!!! Not adding image because size is\" , img.shape[0:2])\n",
    "                    \n",
    "                else :   \n",
    "                    lab_est = [(l.sum()/ef).astype(np.int) for l in lab]\n",
    "\n",
    "                    assert np.allclose(count,lab_est, 0)\n",
    "                \n",
    "                    dataset.append((img,lab,count, im_lab))\n",
    "                    \n",
    "                    print(\"lab_est\", lab_est, \"img shape\", img.shape, \"label shape\", lab.shape)\n",
    "                    sys.stdout.flush()\n",
    "                    \n",
    "        print(\"dataset size\", len(dataset))\n",
    "                    \n",
    "    print(\"writing\", datasetfilename)\n",
    "    out = open(datasetfilename, \"wb\",0)\n",
    "    pickle.dump(dataset, out)\n",
    "    out.close()\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# grab the data from the data set\n",
    "np.random.shuffle(dataset)\n",
    "\n",
    "np_dataset_x = np.asarray([d[0] for d in dataset], dtype=np.float32)\n",
    "np_dataset_y = np.asarray([d[1] for d in dataset], dtype=np.float32)\n",
    "np_dataset_c = np.asarray([d[2] for d in dataset], dtype=np.float32)\n",
    "np_dataset_l = np.asarray([d[3] for d in dataset], dtype=np.float32)\n",
    "\n",
    "# np_dataset_x = np_dataset_x.transpose((0,3,1,2))\n",
    "\n",
    "print(\"np_dataset_x\", np_dataset_x.shape)\n",
    "print(\"np_dataset_y\", np_dataset_y.shape)\n",
    "print(\"np_dataset_c\", np_dataset_c.shape)\n",
    "print(\"np_dataset_l\", np_dataset_l.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "length = len(np_dataset_x)\n",
    "\n",
    "# 2/3 vs 1/3 for training and validation\n",
    "n = int (args.nsamples / 3); \n",
    "\n",
    "np_dataset_x_train = np_dataset_x[0:2*n]\n",
    "np_dataset_y_train = np_dataset_y[0:2*n]\n",
    "np_dataset_c_train = np_dataset_c[0:2*n]\n",
    "np_dataset_l_train = np_dataset_l[0:2*n]\n",
    "print(\"np_dataset_x_train\", len(np_dataset_x_train))\n",
    "\n",
    "np_dataset_x_valid = np_dataset_x[2*n:3*n]\n",
    "np_dataset_y_valid = np_dataset_y[2*n:3*n]\n",
    "np_dataset_c_valid = np_dataset_c[2*n:3*n]\n",
    "np_dataset_l_valid = np_dataset_l[2*n:3*n]\n",
    "print(\"np_dataset_x_valid\", len(np_dataset_x_valid))\n",
    "\n",
    "np_dataset_x_test = np_dataset_x[3*n:]\n",
    "np_dataset_y_test = np_dataset_y[3*n:]\n",
    "np_dataset_c_test = np_dataset_c[3*n:]\n",
    "np_dataset_l_test = np_dataset_l[3*n:]\n",
    "print(\"np_dataset_x_test\", len(np_dataset_x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot 2 images to chcek that the labels are correct \n",
    "# DEBUG:\n",
    "# image\n",
    "plt.Figure(figsize=(5, 3), dpi=300)\n",
    "plt.subplot(131)\n",
    "img1 = np.array(np_dataset_x_train[1, ].reshape(input_shape), dtype=np.float32).astype(np.uint8)\n",
    "plt.imshow(img1, cmap=plt.get_cmap('gray'))\n",
    "# label\n",
    "plt.subplot(132)\n",
    "img2 = np.array(np_dataset_y_train[1, ].reshape(ext_shape), dtype=np.float32).astype(np.uint8)[:,:,0]\n",
    "plt.imshow(img2[int(patch_size/2):-int(patch_size/2), int(patch_size/2):-int(patch_size/2)])\n",
    "plt.subplot(133)\n",
    "# img3 = np.array(np_dataset_l_train[0, ].reshape((320, 320)), dtype=np.float32).astype(np.uint8)\n",
    "img3 = np_dataset_l_train[1, ].reshape((256, 256))\n",
    "plt.imshow(img3, cmap=plt.get_cmap('gray'))\n",
    "# print(img3[patch_size:-patch_size, patch_size:-patch_size])\n",
    "\n",
    "\n",
    "print(np.sum(img3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define data preparation\n",
    "shift = 0.1\n",
    "datagen = ImageDataGenerator(featurewise_center=False, \n",
    "                             featurewise_std_normalization=False, \n",
    "                             # zca_whitening=True, \n",
    "                             # rotation_range=90,\n",
    "                             width_shift_range=shift, \n",
    "                             height_shift_range=shift,\n",
    "                             fill_mode = 'constant',\n",
    "                             cval = 0,\n",
    "                             horizontal_flip=True, \n",
    "                             vertical_flip=True)\n",
    "# fit parameters from data\n",
    "\n",
    "print(np_dataset_x_train.shape, np_dataset_x_train.transpose((0, 2,3,1)).shape)\n",
    "\n",
    "datagen.fit(np_dataset_x_train)\n",
    "# configure batch size and retrieve one batch of images\n",
    "for X_batch, y_batch in datagen.flow(np_dataset_x_train, np_dataset_y_train, batch_size=9):\n",
    "    # , save_to_dir='images', save_prefix='aug', save_format='png'):\n",
    "    print(X_batch.shape)  \n",
    "    # create a grid of 3x3 images\n",
    "    for i in range(0, 9):\n",
    "        plt.subplot(330 + 1 + i)\n",
    "        img = np.array(X_batch[i].reshape(framesize, framesize, 3), dtype=np.float32).astype(np.uint8)\n",
    "        print(img.shape)  \n",
    "        plt.imshow(img, cmap=plt.get_cmap('gray'))\n",
    "    # show the plot\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np_dataset_l_train = np_dataset_l_train.transpose([0,2,3,1])\n",
    "np_dataset_l_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# in case of images and labels we have to use the following approach: \n",
    "# create 2 instances with the same arguments: \n",
    "shift = 0.02\n",
    "image_data_gen_args = dict(featurewise_center=False, \n",
    "                             featurewise_std_normalization=False, \n",
    "                             # zca_whitening=True, \n",
    "                             rotation_range=90,\n",
    "                             width_shift_range=shift, \n",
    "                             height_shift_range=shift,\n",
    "                             fill_mode = 'constant',\n",
    "                             cval = 0,\n",
    "                             horizontal_flip=True, \n",
    "                             vertical_flip=True)\n",
    "datagen = ImageDataGenerator(**image_data_gen_args)\n",
    "labelgen = ImageDataGenerator(**image_data_gen_args)\n",
    "\n",
    "seed = args.seed\n",
    "datagen.fit(np_dataset_x_train, augment=True, seed=seed)\n",
    "# change this one to labels\n",
    "labelgen.fit(np_dataset_l_train, augment=True, seed=seed)\n",
    "\n",
    "image_generator = datagen.flow(\n",
    "    np_dataset_x_train,\n",
    "    seed=seed, \n",
    "    save_to_dir='data/aug', save_prefix='cells', save_format='png')\n",
    "label_generator = labelgen.flow(\n",
    "    np_dataset_l_train,\n",
    "    seed=seed,\n",
    "    save_to_dir='data/aug', save_prefix='dots', save_format='png')\n",
    "\n",
    "# plt.rcParams['figure.figsize'] = (9, 5)\n",
    "\n",
    "num_batches = 3\n",
    "j_batch = 0\n",
    "for X_batch, y_batch in zip(image_generator, label_generator):\n",
    "    j_batch += 1;\n",
    "    # , save_to_dir='images', save_prefix='aug', save_format='png'): \n",
    "    # create a grid of 3x3 images\n",
    "    for i in range(0, 3):\n",
    "        plt.subplot(9, 2, 0 + 1 + 2*i) \n",
    "        plt.figsize=(18, 9)\n",
    "        img = np.array(X_batch[i].reshape(framesize, framesize, 3), dtype=np.float32).astype(np.uint8)\n",
    "        plt.imshow(img, cmap=plt.get_cmap('gray'))\n",
    "\n",
    "        plt.subplot(9, 2, 0 + 1 + 2*i + 1) \n",
    "        img = np.array(y_batch[i].reshape(framesize, framesize, 1), dtype=np.float32).astype(np.uint8)[:, :, 0]\n",
    "\n",
    "        print(img.shape)\n",
    "\n",
    "        plt.imshow(img, cmap=plt.get_cmap('gray'))          \n",
    "    # show the plot\n",
    "    plt.show()\n",
    "    if (j_batch >= num_batches):\n",
    "        break\n",
    "\n",
    "\n",
    "# combine generators into one which yields image and masks\n",
    "# train_generator = zip(image_generator, mask_generator)\n",
    "# model.fit_generator( train_generator, \n",
    "#     steps_per_epoch=2000,\n",
    "#     epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# examples of the images from the training set \n",
    "n_images_show = 7\n",
    "plt.rcParams['figure.figsize'] = (15, 5)\n",
    "plt.title(\"Example images\")\n",
    "plt.imshow(np.concatenate(image_generator[:n_images_show].astype(np.uint8),axis=1), interpolation='none');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "?image_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
