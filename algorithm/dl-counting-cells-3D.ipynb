{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 3D extension of the countception network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys,os,time,random\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg');\n",
    "import matplotlib.pyplot as plt\n",
    "plt.set_cmap('jet');\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import skimage\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "from skimage.io import imread, imsave\n",
    "import pickle\n",
    "import scipy\n",
    "\n",
    "from os import walk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# KERAS stuff \n",
    "from __future__ import print_function\n",
    "import keras \n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Input\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Conv3D, MaxPooling3D\n",
    "from keras.layers.convolutional import ZeroPadding2D, ZeroPadding3D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Concatenate\n",
    "\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keras 2.0.6\n",
      "tensorflow 1.3.0\n"
     ]
    }
   ],
   "source": [
    "print(\"keras\", keras.__version__)\n",
    "print(\"tensorflow\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow\n",
      "tf\n",
      "channels_last\n"
     ]
    }
   ],
   "source": [
    "# check the backend the ordering of the channels\n",
    "print(keras.backend.backend())\n",
    "print(keras.backend.image_dim_ordering())\n",
    "print(K.image_data_format())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/gpu:0']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup for the gpu: \n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
    "\n",
    "get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# check the output of the command above\n",
    "tf.device(\"/gpu:0\")\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "# this pone should help with the images of the large size\n",
    "config = tf.ConfigProto(allow_soft_placement=True)\n",
    "config.gpu_options.allocator_type = 'BFC'\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this part is necessary to set the params from the command line\n",
    "import sys\n",
    "import argparse\n",
    "\n",
    "if len(sys.argv) == 3 and sys.argv[1] == \"-f\": #on jupyter\n",
    "    sys.argv = ['']\n",
    "    \n",
    "parser = argparse.ArgumentParser(description='Count-ception')\n",
    "\n",
    "parser.add_argument('-seed', type=int, nargs='?',default=0, help='random seed for split and init')\n",
    "parser.add_argument('-nsamples', type=int, nargs='?',default=32, help='Number of samples (N) in train and valid')\n",
    "# TODO: Is it used ? \n",
    "parser.add_argument('-stride', type=int, nargs='?',default=1, help='The args.stride at the initial layer')\n",
    "# TODO: Is it used ?\n",
    "parser.add_argument('-lr', type=float, nargs='?',default=0.00005, help='This will set the learning rate ')\n",
    "parser.add_argument('-kern', type=str, nargs='?',default=\"sq\", help='This can be gaus or sq')\n",
    "parser.add_argument('-cov', type=float, nargs='?',default=1, help='This is the covariance when kern=gaus')\n",
    "parser.add_argument('-scale', type=int, nargs='?',default=1, help='Scale the input image and labels')\n",
    "parser.add_argument('-data', type=str, nargs='?',default=\"cells\", help='Dataset folder')\n",
    "parser.add_argument('-framesize', type=int, nargs='?',default=256, help='Size of the images processed at once')\n",
    "\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(cov=1, data='cells', framesize=256, kern='sq', lr=5e-05, nsamples=3, scale=1, seed=0, stride=1)\n",
      "channels_last\n"
     ]
    }
   ],
   "source": [
    "# set the passed parameters here if you forgot them\n",
    "args.framesize = 256\n",
    "args.scale = 1\n",
    "args.nsamples = 3\n",
    "\n",
    "print(args)\n",
    "print(keras.backend.image_data_format())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# how much to extend the initial image \n",
    "patch_size_w = int(16)\n",
    "patch_size_h = int(16)\n",
    "patch_size_d = int(16) # in the real example this one should be 8\n",
    "framesize = int(args.framesize/args.scale)\n",
    "channels = int(1)\n",
    "framesize_h = int(256)\n",
    "framesize_w = int(256)\n",
    "framesize_d = int(27) # in the real example this one should be 27\n",
    "noutputs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-16-cells-sq1_params.p\n",
      "1-16-256-sq1-cells-1-dataset.p\n"
     ]
    }
   ],
   "source": [
    "paramfilename = str(args.scale) + \"-\" + str(patch_size_w) + \"-\" + args.data + \"-\" + args.kern + str(args.cov) + \"_params.p\"\n",
    "datasetfilename = str(args.scale) + \"-\" + str(patch_size_w) + \"-\" + str(framesize) + \"-\" + args.kern + str(args.stride) + \"-\" + args.data + \"-\" + str(args.cov) + \"-dataset.p\"\n",
    "print(paramfilename)\n",
    "print(datasetfilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#reproducibility\n",
    "random.seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "tf.set_random_seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# input shape is the image shape without the pathces\n",
    "input_shape = (framesize_w, framesize_h, framesize_d, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[272, 272, 43]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the input dimensions for the network\n",
    "[x + y for x, y in zip(input_shape[0:3], (patch_size_w, patch_size_h, patch_size_d))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# custom loss funciton\n",
    "def mae_loss(y_true, y_pred):\n",
    "    # mae_loss might be too \"greedy\" and train the network on artifacts\n",
    "    # prediction_count2 = np.sum(y_pred / ef)\n",
    "    # mae_loss = K.sum(K.abs(prediction_count2 - (y_true/ef)))\n",
    "    #Mean Absolute Error is computed between each count of the count map\n",
    "    l1_loss = K.abs(y_pred - y_true)\n",
    "    loss = K.mean(l1_loss)    \n",
    "    return loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# custom layers (building blocks)\n",
    "def ConvFactory1(data, num_filters, filter_size, stride=1, pad=(0, 0, 0), nonlinearity=LeakyReLU(alpha=0.3)):\n",
    "    # data is the input tensor, leaky rely as a nonlinearity\n",
    "    # the padding is done in the first layer automatically! \n",
    "    # no need to preprocess the data\n",
    "    data = ZeroPadding3D(padding = pad, data_format=None, input_shape=input_shape)(data)\n",
    "    data = Conv3D(filters = num_filters, kernel_size = (filter_size, filter_size, filter_size), kernel_initializer='glorot_uniform')(data)\n",
    "    data = LeakyReLU(alpha=0.3)(data)\n",
    "    data = BatchNormalization()(data)\n",
    "    return data\n",
    "    \n",
    "def SimpleFactory1(data, ch_1x1, ch_3x3):\n",
    "    # used for double layers \n",
    "    conv1x1 = ConvFactory1(data, filter_size=1, pad=0, num_filters=ch_1x1)\n",
    "    conv3x3 = ConvFactory1(data, filter_size=3, pad=1, num_filters=ch_3x3) \n",
    "    concat = Concatenate()([conv1x1, conv3x3])\n",
    "    return concat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: check again?\n",
    "def create_model(input_shape):\n",
    "    main_input = Input(shape=input_shape, name='main_input')\n",
    "    # print (net.shape)\n",
    "    net = ConvFactory1(main_input, num_filters=64, pad=(patch_size_w, patch_size_h, patch_size_d), filter_size = 3)\n",
    "    print (net.shape)\n",
    "    net = SimpleFactory1(net, ch_1x1 = 16, ch_3x3 = 16)\n",
    "    print (net.shape)\n",
    "    net = SimpleFactory1(net, ch_1x1 = 16, ch_3x3 = 32)\n",
    "    print (net.shape)\n",
    "    net = ConvFactory1(net, num_filters=16, filter_size = 14)\n",
    "    print (net.shape)\n",
    "    net = SimpleFactory1(net, ch_1x1 = 112, ch_3x3 = 48)\n",
    "    print (net.shape)\n",
    "    net = SimpleFactory1(net, ch_1x1 = 40, ch_3x3 = 40)\n",
    "    print (net.shape)\n",
    "    net = SimpleFactory1(net, ch_1x1 = 32, ch_3x3 = 96)\n",
    "    print (net.shape)\n",
    "\n",
    "    net = ConvFactory1(net, num_filters=16, filter_size = 18)\n",
    "    print (net.shape) \n",
    "    net = ConvFactory1(net, num_filters=64, filter_size = 1)\n",
    "    print (net.shape) \n",
    "    net = ConvFactory1(net, num_filters=64, filter_size = 1)\n",
    "    print (net.shape) \n",
    "    main_output = ConvFactory1(net, filter_size=1, num_filters=1)\n",
    "    print (main_output.shape)\n",
    "    \n",
    "    model = Model(inputs=[main_input], outputs = main_output)  \n",
    "    # mean_absolute_error\n",
    "    model.compile(loss=mae_loss, optimizer='sgd', metrics=['accuracy'])\n",
    "         \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 286, 286, 57, 64)\n",
      "(?, 286, 286, 57, 32)\n",
      "(?, 286, 286, 57, 48)\n",
      "(?, 273, 273, 44, 16)\n",
      "(?, 273, 273, 44, 160)\n",
      "(?, 273, 273, 44, 80)\n",
      "(?, 273, 273, 44, 128)\n",
      "(?, 256, 256, 27, 16)\n",
      "(?, 256, 256, 27, 64)\n",
      "(?, 256, 256, 27, 64)\n",
      "(?, 256, 256, 27, 1)\n"
     ]
    }
   ],
   "source": [
    "model = create_model(input_shape = input_shape)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "network output size should be [272, 272, 43]\n"
     ]
    }
   ],
   "source": [
    "#sanity check\n",
    "print(\"network output size should be\", [x + y for x, y in zip(input_shape[0:3], (patch_size_w, patch_size_h, patch_size_d))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ef 4096.0\n"
     ]
    }
   ],
   "source": [
    "# TODO: FIX THE EF COEFFICINT FOR THE CASE OF CUBE \n",
    "if (args.kern == \"sq\"):\n",
    "    ef = ((patch_size_w/args.stride)**3.0)\n",
    "elif (args.kern == \"gaus\"):\n",
    "    ef = 1.0\n",
    "print(\"ef\", ef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.153915405273438e-05 sec\n",
      "7.772445678710938e-05 sec\n"
     ]
    }
   ],
   "source": [
    "# test run\n",
    "train_start_time = time.time()\n",
    "# model.fit(np.zeros([1, input_shape[0], input_shape[1], input_shape[2], input_shape[3]]), \n",
    "#          np.zeros([1, input_shape[0] + patch_size_w, input_shape[1] + patch_size_h, input_shape[2] + patch_size_d, 1]))\n",
    "print(time.time() - train_start_time, \"sec\")\n",
    "\n",
    "train_start_time = time.time()\n",
    "# model.predict();\n",
    "print(time.time() - train_start_time, \"sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fucntions to see the results \n",
    "def genGausImage(framesize, mx, my, mz, cov=1):  \n",
    "    framesize_x = framesize[0]\n",
    "    framesize_y = framesize[1]\n",
    "    framesize_z = framesize[2]\n",
    "    \n",
    "    x, y, z = np.mgrid[0:framesize_x, 0:framesize_y, 0:framesize_z]\n",
    "    pos = np.dstack((x, y, z))\n",
    "    mean = [mx, my, mz]\n",
    "    cov = [[cov, 0, 0], [0, cov, 0], [0, 0, cov]]\n",
    "    rv = scipy.stats.multivariate_normal(mean, cov).pdf(pos)\n",
    "    return rv/rv.sum()\n",
    "\n",
    "# TODO: FIX!\n",
    "def getDensity(width, markers):\n",
    "    gaus_img = np.zeros((width,width))\n",
    "    for k in range(width):\n",
    "        for l in range(width):\n",
    "            if (markers[k,l] > 0.5):\n",
    "                gaus_img += genGausImage(len(markers),k-patch_size/2,l-patch_size/2,cov)\n",
    "    return gaus_img\n",
    "\n",
    "def getMarkersCells(labelPath, scale, size):  \n",
    "    labs = imread(labelPath).transpose([1,2,0])\n",
    "    if len(labs.shape) == 3:\n",
    "        lab = labs[:,:,:]/255\n",
    "    elif len(labs.shape) == 4:\n",
    "        lab = labs[:,:,:,0]/255\n",
    "    else:\n",
    "        print(\"unknown label format\")\n",
    "    \n",
    "    binsize = [scale, scale, scale]\n",
    "    out = np.zeros(size)    \n",
    "    for i in range(binsize[0]):\n",
    "        for j in range(binsize[1]):\n",
    "            for k in range(binsize[2]):\n",
    "                out = np.maximum(lab[i::binsize[0], j::binsize[1], k::binsize[2]], out)\n",
    "        \n",
    "    print(lab.sum(),out.sum())\n",
    "    assert np.allclose(lab.sum(),out.sum(), 1)\n",
    "    \n",
    "    return out\n",
    "\n",
    "def getCellCountCells(markers, x, y, z, h, w, d):\n",
    "    types = [0] * noutputs\n",
    "    for i in range(noutputs):\n",
    "        types[i] = (markers[y:y+h,x:x+w, z:z+w] == 1).sum()\n",
    "        #types[i] = (markers[y:y+h,x:x+w] != -1).sum()\n",
    "    return types\n",
    "\n",
    "def getLabelsCells(markers, img_pad, base_x, base_y, base_z, stride, scale):\n",
    "    \n",
    "    height = int ((img_pad.shape[0])/args.stride)\n",
    "    width = int ((img_pad.shape[1])/args.stride)\n",
    "    depth = int ((img_pad.shape[2])/args.stride)\n",
    "    print(\"label size: \", height, width, depth)\n",
    "    labels = np.zeros((noutputs, height, width, depth))\n",
    "    if (args.kern == \"sq\"):\n",
    "        for y in range(0,height):\n",
    "            for x in range(0,width):\n",
    "                for z in range(0, depth):\n",
    "                    count = getCellCountCells(markers, x*args.stride, y*args.stride, z*args.stride, patch_size_w, patch_size_h, patch_size_d)  \n",
    "                    for i in range(0,noutputs):\n",
    "                        labels[i][y][x][z] = count[i]\n",
    "\n",
    "    \n",
    "    elif (args.kern == \"gaus\"):\n",
    "        # gauss is not checked in 3D\n",
    "        for i in range(0,noutputs):\n",
    "            labels[i] = getDensity(width, markers[base_y:base_y+width,base_x:base_x+width, base_z:base_z+depth])\n",
    "    \n",
    "    \n",
    "    print(\"getLabelsCells: DONE!\")\n",
    "    \n",
    "    count_total = getCellCountCells(markers, 0, 0, 0, framesize_h+patch_size_h, framesize_w+patch_size_w, framesize_d+patch_size_d)\n",
    "    return labels, count_total\n",
    "\n",
    "def getTrainingExampleCells(img_raw, framesize_w, framesize_h, framesize_d, labelPath, base_x,  base_y, base_z, stride, scale):\n",
    "    \n",
    "    img = img_raw[base_y:base_y+framesize_h, base_x:base_x+framesize_w, base_z:base_z+framesize_d]\n",
    "    img_pad = np.pad(img[:,:,:], ((int ((patch_size_w)/2), int ((patch_size_w)/2)), \n",
    "                                     (int ((patch_size_h)/2), int ((patch_size_h)/2)), \n",
    "                                     (int ((patch_size_d)/2), int ((patch_size_d)/2))), \"constant\")\n",
    "    \n",
    "    markers = getMarkersCells(labelPath, scale, img_raw.shape[0:3])\n",
    "    markers = markers[base_y:base_y+framesize_h, base_x:base_x+framesize_w, base_z:base_z+framesize_d]\n",
    "    markers = np.pad(markers, ((patch_size_w, patch_size_w), \n",
    "                               (patch_size_h, patch_size_h), \n",
    "                               (patch_size_d, patch_size_d)), \"constant\", constant_values=-1)\n",
    "    \n",
    "    labels, count  = getLabelsCells(markers, img_pad, base_x, base_y, base_z, args.stride, scale)\n",
    "    return img, labels, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full path: /home/milkyklim/dl-cell-counting/algorithm/data/test-cells-3D\n"
     ]
    }
   ],
   "source": [
    "# read the files from the test folder \n",
    "import glob\n",
    "\n",
    "# prefix = '/Users/kkolyva/'\n",
    "prefix = '/home/milkyklim/'\n",
    "folder = prefix + 'dl-cell-counting/algorithm/data/test-cells-3D'\n",
    "img_ext = '.tif'\n",
    "\n",
    "print('Full path:', folder)\n",
    "\n",
    "imgs = []\n",
    "\n",
    "for filename in glob.iglob(folder + \"/*dots\" + img_ext):\n",
    "    imgg = filename.replace(\"dots\",\"cell\")\n",
    "    imgs.append([imgg,filename])\n",
    "    \n",
    "if len(imgs) == 0:\n",
    "    print(\"Issue with dataset\")\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/milkyklim/dl-cell-counting/algorithm/data/test-cells-3D/002cell.tif\n",
      "/home/milkyklim/dl-cell-counting/algorithm/data/test-cells-3D/002dots.tif\n",
      "(27, 256, 256)\n",
      "256 256 27\n",
      "(256, 256, 27)  ->>>> (256, 256, 27)\n",
      "img_raw (256, 256, 27)\n",
      "13.0 13.0\n",
      "label size:  288 288 59\n"
     ]
    }
   ],
   "source": [
    "# code to debug the data generation\n",
    "# adjust the size of the images and labels + check the output of the network\n",
    "idx = 0\n",
    "plt.rcParams['figure.figsize'] = (18, 9)\n",
    "imgPath,labelPath,x,y,z = imgs[idx][0], imgs[idx][1], 0, 0, 0\n",
    "\n",
    "print(imgPath)\n",
    "print(labelPath)\n",
    "\n",
    "im = imread(imgPath)\n",
    "print(im.shape)\n",
    "\n",
    "\n",
    "img_raw_raw = im.transpose([1,2,0]) #grayscale\n",
    "\n",
    "# plt.imshow(img_raw_raw[:,:,1,:], interpolation='none',cmap='Greys_r');\n",
    "\n",
    "print (img_raw_raw.shape[0], img_raw_raw.shape[1], img_raw_raw.shape[2])\n",
    "# size_scaled = (int(img_raw_raw.shape[0]/args.scale), \n",
    "#                int(img_raw_raw.shape[1]/args.scale), \n",
    "#                int(img_raw_raw.shape[2]/args.scale), 1)\n",
    "\n",
    "# print(size_scaled)\n",
    "# img_raw = scipy.ndimage.zoom(img_raw_raw[:,:,:,:],size_scaled)\n",
    "# img_raw = scipy.misc.imresize(img_raw_raw[:,:,:,:], size_scaled, mode='RGB')\n",
    "img_raw = img_raw_raw\n",
    "print(img_raw_raw.shape,\" ->>>>\", img_raw.shape)\n",
    "\n",
    "# plt.imshow(img_raw[:,:,1,:], interpolation='none',cmap='Greys_r');\n",
    "\n",
    "print(\"img_raw\", img_raw.shape)\n",
    "img, lab, count = getTrainingExampleCells(img_raw, framesize_w, framesize_h, framesize_d, labelPath, x, y, z, args.stride, args.scale)\n",
    "print(\"count\", count)\n",
    "\n",
    "markers = getMarkersCells(labelPath, args.scale, img_raw.shape[0:3])\n",
    "markers = markers[y:y+framesize_h, x:x+framesize_w, z:z+framesize_d]\n",
    "count = getCellCountCells(markers, 0, 0, 0, framesize_w,framesize_h, framesize_d)\n",
    "print(\"count\", count, 'markers max', markers.max())\n",
    "\n",
    "# # pcount = model.predict(np.array([img]), batch_size=1)\n",
    "\n",
    "lab_est = [(l.sum()/ef).astype(np.int) for l in lab]\n",
    "# # pred_est = [(l.sum()/ef).astype(np.int) for l in pcount]\n",
    "\n",
    "print(\"img shape\",  img.shape)\n",
    "print(\"label shape\", lab.shape)\n",
    "print(\"label est\", lab_estgetTrainingExampleCells)\n",
    "# print(\"label est \",lab_est,\" --> predicted est \",pred_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# put some /show images/ here to see the result of processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for path in imgs: \n",
    "    if (not os.path.isfile(path[0])):\n",
    "        print(path, \"bad\", path[0])\n",
    "    if (not os.path.isfile(path[1])):\n",
    "        print(path, \"bad\", path[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading 1-16-256-sq1-cells-1-dataset.p\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "dataset = []\n",
    "if (os.path.isfile(datasetfilename)):\n",
    "    print(\"reading\", datasetfilename)\n",
    "    dataset = pickle.load(open(datasetfilename, \"rb\" ))\n",
    "else:\n",
    "    dataset_x = []\n",
    "    dataset_y = []\n",
    "    dataset_c = []\n",
    "    print(len(imgs))\n",
    "    for path in imgs: \n",
    "\n",
    "        imgPath = path[0]\n",
    "        print(imgPath)\n",
    "\n",
    "        im = imread(imgPath)\n",
    "        img_raw_raw = im.transpose([1,2,0])\n",
    "        \n",
    "        # img_raw = scipy.misc.imresize(img_raw_raw, (int(img_raw_raw.shape[0]/args.scale),int(img_raw_raw.shape[1]/args.scale)))\n",
    "        img_raw = img_raw_raw\n",
    "        print(img_raw_raw.shape,\" ->>>>\", img_raw.shape)\n",
    "\n",
    "        labelPath = path[1]\n",
    "        for base_x in range(0,img_raw.shape[0],framesize_h):\n",
    "            for base_y in range(0,img_raw.shape[1],framesize_w):\n",
    "                for base_z in range(0,img_raw.shape[2],framesize_d):\n",
    "\n",
    "                    if (img_raw.shape[1] - base_y < framesize_w) or (img_raw.shape[0] - base_x < framesize_h) or (img_raw.shape[2] - base_z < framesize_d):\n",
    "                        print(\"!!!! Not adding image because size is\" , img_raw.shape[1] - base_y, img_raw.shape[0] - base_x, img_raw.shape[2] - baze_z)\n",
    "                        continue\n",
    "\n",
    "                    img, lab, count = getTrainingExampleCells(img_raw, framesize_w, framesize_h, framesize_d, labelPath, base_y, base_x, base_z, args.stride, args.scale)\n",
    "                    print(\"count \", count)\n",
    "\n",
    "                    if img.shape[0:3] != (framesize_w,framesize_h, framesize_d):\n",
    "                        print(\"!!!! Not adding image because size is\" , img.shape[0:3])\n",
    "\n",
    "                    else :   \n",
    "                        lab_est = [(l.sum()/ef).astype(np.int) for l in lab]\n",
    "\n",
    "                        print(\"lab_est \", lab_est)\n",
    "                        \n",
    "                        assert np.allclose(count,lab_est, 0)\n",
    "\n",
    "                        dataset.append((img,lab,count))\n",
    "\n",
    "                        print(\"lab_est\", lab_est, \"img shape\", img.shape, \"label shape\", lab.shape)\n",
    "                        sys.stdout.flush()\n",
    "                    \n",
    "        print(\"dataset size\", len(dataset))\n",
    "                    \n",
    "    print(\"writing\", datasetfilename)\n",
    "    out = open(datasetfilename, \"wb\",0)\n",
    "    pickle.dump(dataset, out)\n",
    "    out.close()\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np_dataset_x (3, 256, 256, 27)\n",
      "np_dataset_y (3, 1, 272, 272, 43)\n",
      "np_dataset_c (3, 1)\n"
     ]
    }
   ],
   "source": [
    "# grab the data from the data set\n",
    "np.random.shuffle(dataset)\n",
    "\n",
    "np_dataset_x = np.asarray([d[0] for d in dataset], dtype=np.float32)\n",
    "np_dataset_y = np.asarray([d[1] for d in dataset], dtype=np.float32)\n",
    "np_dataset_c = np.asarray([d[2] for d in dataset], dtype=np.float32)\n",
    "\n",
    "np_dataset_x = np_dataset_x # .transpose((0,3,1,2))\n",
    "\n",
    "print(\"np_dataset_x\", np_dataset_x.shape)\n",
    "print(\"np_dataset_y\", np_dataset_y.shape)\n",
    "print(\"np_dataset_c\", np_dataset_c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np_dataset_x_train 2\n",
      "np_dataset_x_valid 1\n",
      "np_dataset_x_test 0\n"
     ]
    }
   ],
   "source": [
    "length = len(np_dataset_x)\n",
    "\n",
    "# 2/3 vs 1/3 for training and validation\n",
    "n = int (args.nsamples / 3); \n",
    "\n",
    "np_dataset_x_train = np_dataset_x[0:2*n]\n",
    "np_dataset_y_train = np_dataset_y[0:2*n]\n",
    "np_dataset_c_train = np_dataset_c[0:2*n]\n",
    "print(\"np_dataset_x_train\", len(np_dataset_x_train))\n",
    "\n",
    "np_dataset_x_valid = np_dataset_x[2*n:3*n]\n",
    "np_dataset_y_valid = np_dataset_y[2*n:3*n]\n",
    "np_dataset_c_valid = np_dataset_c[2*n:3*n]\n",
    "print(\"np_dataset_x_valid\", len(np_dataset_x_valid))\n",
    "\n",
    "np_dataset_x_test = np_dataset_x[3*n:]\n",
    "np_dataset_y_test = np_dataset_y[3*n:]\n",
    "np_dataset_c_test = np_dataset_c[3*n:]\n",
    "print(\"np_dataset_x_test\", len(np_dataset_x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np_dataset_x_train 1\n",
      "np_dataset_x_valid 1\n",
      "np_dataset_x_test 1\n"
     ]
    }
   ],
   "source": [
    "length = len(np_dataset_x)\n",
    "\n",
    "# 2/3 vs 1/3 for training and validation\n",
    "n = 0 # int (args.nsamples / 3); \n",
    "\n",
    "np_dataset_x_train = np_dataset_x[0:1]\n",
    "np_dataset_y_train = np_dataset_y[0:1]\n",
    "np_dataset_c_train = np_dataset_c[0:1]\n",
    "print(\"np_dataset_x_train\", len(np_dataset_x_train))\n",
    "\n",
    "np_dataset_x_valid = np_dataset_x[1:2]\n",
    "np_dataset_y_valid = np_dataset_y[1:2]\n",
    "np_dataset_c_valid = np_dataset_c[1:2]\n",
    "print(\"np_dataset_x_valid\", len(np_dataset_x_valid))\n",
    "\n",
    "np_dataset_x_test = np_dataset_x[2:]\n",
    "np_dataset_y_test = np_dataset_y[2:]\n",
    "np_dataset_c_test = np_dataset_c[2:]\n",
    "print(\"np_dataset_x_test\", len(np_dataset_x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of counts total  39.0\n",
      "number of counts on average  13.0 +- 0.0\n",
      "counts min: 13.0 max: 13.0\n"
     ]
    }
   ],
   "source": [
    "# some stats before the run\n",
    "print(\"number of counts total \", np_dataset_c.sum())\n",
    "print(\"number of counts on average \", np_dataset_c.mean(), \"+-\", np_dataset_c.std())\n",
    "print(\"counts min:\", np_dataset_c.min(), \"max:\", np_dataset_c.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# examples of the images from the training set \n",
    "n_images_show = 7\n",
    "plt.rcParams['figure.figsize'] = (15, 5)\n",
    "plt.title(\"Example images\")\n",
    "plt.imshow(np.concatenate(np_dataset_x_train[:n_images_show].astype(np.uint8).transpose((0,2,3,1)),axis=1), interpolation='none');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.title(\"Example images\")\n",
    "plt.imshow(np.concatenate(np_dataset_y_train[:n_images_show,0],axis=1), interpolation='none');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2oAAAE/CAYAAAA39zBmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYAQ1AACAwfx/+gT3N4ng3lcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7faf787a93c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams['figure.figsize'] = (15, 5)\n",
    "plt.title(\"Counts in each image\")\n",
    "plt.bar(range(len(np_dataset_c_train)),np_dataset_c_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total cells in training [ 13.]\n",
      "Total cells in validation [ 13.]\n",
      "Total cells in testing [ 13.]\n"
     ]
    }
   ],
   "source": [
    "# some stats again\n",
    "print(\"Total cells in training\", np.sum(np_dataset_c_train[0:], axis=0))\n",
    "print(\"Total cells in validation\", np.sum(np_dataset_c_valid[0:], axis=0))\n",
    "print(\"Total cells in testing\", np.sum(np_dataset_c_test[0:], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "directory = \"network-temp/\"\n",
    "model_ext = \"-countception.h5py\"\n",
    "\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "def save_network(net, name):\n",
    "    net.save(directory + str(name) + model_ext)\n",
    "    \n",
    "# pay attention to the loss function    \n",
    "def load_network(name):\n",
    "    return load_model(directory + str(name) + model_ext, custom_objects={'mae_loss': mae_loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected main_input to have 5 dimensions, but got array with shape (1, 256, 256, 27)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-d3377244011d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m           \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m           \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m           validation_data=(np_dataset_x_valid.transpose((0,2,3,1)), np_dataset_y_valid.transpose((0,2,3,4,1))))\n\u001b[0m",
      "\u001b[0;32m/home/milkyklim/anaconda/envs/python3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1356\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1358\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1359\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/milkyklim/anaconda/envs/python3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[1;32m   1232\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1233\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1234\u001b[0;31m                                     exception_prefix='input')\n\u001b[0m\u001b[1;32m   1235\u001b[0m         y = _standardize_input_data(y, self._feed_output_names,\n\u001b[1;32m   1236\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/milkyklim/anaconda/envs/python3/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    126\u001b[0m                                  \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m                                  \u001b[0;34m' dimensions, but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m                                  str(array.shape))\n\u001b[0m\u001b[1;32m    129\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_dim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected main_input to have 5 dimensions, but got array with shape (1, 256, 256, 27)"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "batch_size = 4\n",
    "\n",
    "model.fit(np_dataset_x_train.transpose((0,2,3,1)), np_dataset_y_train.transpose((0,2,3,4, 1)),\n",
    "          epochs = num_epochs,\n",
    "          batch_size = batch_size,\n",
    "          validation_data=(np_dataset_x_valid.transpose((0,2,3,1)), np_dataset_y_valid.transpose((0,2,3,4,1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
